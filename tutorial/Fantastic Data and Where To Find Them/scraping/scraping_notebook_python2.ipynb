{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of great data out on the web. Unfortunately, it is not all readily available via APIs. And even when APIs are available, it may restrict the data we have access to. Scraping usually refers to extracting web page content when APIs are not available. \n",
    "\n",
    "In the API section, we used urllib to call an API and save data. We can also use it to aid in our extraction of data from webpages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "html = urllib.urlopen(\"http://xkcd.com/1481/\")\n",
    "print(html.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the urlretrieve function to retrieve a specific resources, such as a file, via url. This is basic web scraping.\n",
    "\n",
    "If we look through our html above, we can see there is a url for the image in the page. (Look for: ```Image URL (for hotlinking/embedding): https://imgs.xkcd.com/comics/api.png```)\n",
    "\n",
    "But before we go doing that, maybe we should check the robots.txt file first..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = urllib.urlopen(\"https://xkcd.com/robots.txt\")\n",
    "print(robot.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we are good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.urlretrieve(\"http://imgs.xkcd.com/comics/api.png\", \"api.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below this is markdown. Double-click on it so it is in editing mode, then execute it to display the file you downloaded with the previous command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](api.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Using these methods, we are treating the html as an unstructured string. If we want to retrieve the structured markup, we can use [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/). \"Beautiful Soup is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It commonly saves programmers hours or days of work.\"\n",
    "\n",
    "Let's look at [this page](https://litemind.com/best-famous-quotes). What if we wanted to extract the quotes and authors? First, are we allowed to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = urllib.urlopen(\"https://litemind.com/robots.txt\")\n",
    "print(robot.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The page we are scraping isn't excluded in the robots.txt file. Let's see what Beautiful Soup can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "url = \"https://litemind.com/best-famous-quotes\"\n",
    "\n",
    "html = urllib.urlopen(url).read()\n",
    "soup = BeautifulSoup(html,\"html.parser\")\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above, we read our web page with urllib (we can also use the [requests](http://docs.python-requests.org/en/master/) library), then parsed with with the Beautiful Soup html parser. You can read about the different parser option [here](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#specifying-the-parser-to-use).\n",
    "\n",
    "Our parsed data is now in a variable called \"soup\". We used the [\"prettify\"](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#output) method to print something a little more readable. Beautiful Soup has represented the html document as a nested data structure that we can navigate.\n",
    "\n",
    "Beautiful Soup lets you access information through tags in the html. The tags are the same as the ones in the document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tags have names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes they have attributes too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup.title.attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But title does not. It does contain a string though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at just the head of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup.body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look through the body, we can see our quotes are contained here, starting after \n",
    "```<h2>Wisdom Quotes</h2>```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.h2.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tags have attributes that allow us to [navigate](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#navigating-the-tree) through the structure of the document as well. We can navigate up and down a document's structure by looking at a tag's child and parent attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.body.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.head.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can go \"sideways\" in a document to look at tags at the same level using sibling. Here we can see that head and body are at the same level in our document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.head.next_sibling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of your document will determine which of these attributes are available.\n",
    "\n",
    "As we saw above, the quotes we want to scrape start after the second heading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.h2.next_sibling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can chain our attributes to continue accessing things. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.h2.next_sibling.next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.h2.next_sibling.next_sibling.next_sibling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems a bit cumbersome though, right?\n",
    "\n",
    "Beautiful Soup also allows us to [search](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree) our document. A common task is to pull all of the URLs linked on a page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in soup.find_all('a'):\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found our quotes before using:\n",
    "```soup.h2.next_sibling.next_sibling.next_sibling```\n",
    "\n",
    "We can also pull them out using find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div', class_='wp_quotepage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can pull them out yet another way by using [CSS Selectors](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select('.wp_quotepage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the elements we are looking for, we can write some code to pull them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for quote in soup.select('.wp_quotepage'):\n",
    "    text = quote.findChildren()[0].renderContents()\n",
    "    author = quote.findChildren()[1].renderContents()\n",
    "    print(text, author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It still isn't perfect, but you can clean it up from there. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of resources out there for building scrapers. Do you have a page you want to scrape? If so, try it out now. We are here to answer your questions so give this a try. If you want some more ideas, here are some resources to take a look at:\n",
    "\n",
    "**More Examples**\n",
    "* [Scotch Notebook](https://github.com/nd1/pycon_2017/blob/master/scraping/scotch.ipynb) - This notebook shows the process I went through to scrape a site. It is not a polished tutorial, but instead shows some of my thought process when I am scraping.\n",
    "* Tutorial for [building your first scraper](http://first-web-scraper.readthedocs.io/en/latest/)\n",
    "* [Python Web Scraping Tutorial using BeautifulSoup](https://www.dataquest.io/blog/web-scraping-tutorial-python/)\n",
    "* [Scraping Marvel Comics](http://blog.nycdatascience.com/student-works/scraping-marvel-comics/)\n",
    "* [Scraping for Craft Beers: A Dataset Creation Tutorial](http://blog.kaggle.com/2017/01/31/scraping-for-craft-beers-a-dataset-creation-tutorial/)\n",
    "\n",
    "**Things to scrape**:\n",
    "Wikipedia has a lot of good lists to practice on like [Billboard Year-End Hot 100 singles of 1960](https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1960), [List of whisky distilleries in Scotland](https://en.wikipedia.org/wiki/List_of_whisky_distilleries_in_Scotland), or [List of highest-grossing Indian films](https://en.wikipedia.org/wiki/List_of_highest-grossing_Indian_films) among [other things](https://en.wikipedia.org/wiki/List_of_lists_of_lists).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
